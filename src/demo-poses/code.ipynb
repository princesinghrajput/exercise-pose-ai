{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "# Load MoveNet model\n",
    "model = hub.load('https://tfhub.dev/google/movenet/singlepose/lightning/4')\n",
    "\n",
    "# Define keypoint names based on MoveNet's known order\n",
    "KEYPOINT_NAMES = [\n",
    "    \"nose\", \"left_eye\", \"right_eye\", \"left_ear\", \"right_ear\", \n",
    "    \"left_shoulder\", \"right_shoulder\", \"left_elbow\", \"right_elbow\",\n",
    "    \"left_wrist\", \"right_wrist\", \"left_hip\", \"right_hip\",\n",
    "    \"left_knee\", \"right_knee\", \"left_ankle\", \"right_ankle\"\n",
    "]\n",
    "\n",
    "def movenet(input_image):\n",
    "    input_image = tf.image.resize_with_pad(tf.expand_dims(input_image, axis=0), 192, 192)\n",
    "    input_image = tf.cast(input_image, dtype=tf.int32)\n",
    "    outputs = model.signatures['serving_default'](input_image)\n",
    "    keypoints = outputs['output_0'].numpy()\n",
    "    return keypoints\n",
    "\n",
    "def serialize_landmarks(keypoints):\n",
    "    serialized = []\n",
    "    for idx, kp in enumerate(keypoints[0, 0, :]):\n",
    "        serialized.append({\n",
    "            'name': KEYPOINT_NAMES[idx],\n",
    "            'x': float(kp[1]),\n",
    "            'y': float(kp[0]),\n",
    "            'score': float(kp[2])\n",
    "        })\n",
    "    return serialized\n",
    "\n",
    "# Load video\n",
    "video = cv2.VideoCapture('demo_video.mp4')\n",
    "demo_poses = []\n",
    "\n",
    "while video.isOpened():\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert the frame to RGB\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    # Process the frame to extract pose\n",
    "    keypoints = movenet(rgb_frame)\n",
    "    serialized_landmarks = serialize_landmarks(keypoints)\n",
    "    demo_poses.append(serialized_landmarks)\n",
    "\n",
    "video.release()\n",
    "\n",
    "# Save the demo poses for future comparison\n",
    "with open('demo_poses.json', 'w') as f:\n",
    "    json.dump({'poses': demo_poses}, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.06053490331318\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def calculate_angle(a,b,c):\n",
    "    a = np.array(a) # First\n",
    "    b = np.array(b) # Mid\n",
    "    c = np.array(c) # End\n",
    "    \n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "    angle = np.abs(radians*180.0/np.pi)\n",
    "    \n",
    "    if angle >180.0:\n",
    "        angle = 360-angle\n",
    "        \n",
    "    return angle \n",
    "\n",
    "angle = calculate_angle([ 0.4246756903701565, 0.3882735731072927 ], [ 0.45501756482551065, 0.4028621332190844 ], [ 0.3768017245637768, 0.27402184631110166 ])\n",
    "print(angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\psingh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\psingh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\psingh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\psingh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\psingh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'nose', 'x': 0.3809781, 'y': 0.53151387, 'score': 0.87499297}, {'name': 'left_eye', 'x': 0.35043752, 'y': 0.562536, 'score': 0.56667644}, {'name': 'right_eye', 'x': 0.34894747, 'y': 0.5005225, 'score': 0.62537974}, {'name': 'left_ear', 'x': 0.3679764, 'y': 0.6071831, 'score': 0.6449508}, {'name': 'right_ear', 'x': 0.367179, 'y': 0.4601211, 'score': 0.6620657}, {'name': 'left_shoulder', 'x': 0.45170206, 'y': 0.67959785, 'score': 0.739439}, {'name': 'right_shoulder', 'x': 0.44737315, 'y': 0.39777395, 'score': 0.87130123}, {'name': 'left_elbow', 'x': 0.29085112, 'y': 0.70728415, 'score': 0.8915762}, {'name': 'right_elbow', 'x': 0.2888388, 'y': 0.35413033, 'score': 0.6532154}, {'name': 'left_wrist', 'x': 0.12878864, 'y': 0.5653012, 'score': 0.71840924}, {'name': 'right_wrist', 'x': 0.13008459, 'y': 0.48835444, 'score': 0.6074091}, {'name': 'left_hip', 'x': 0.7775527, 'y': 0.6293003, 'score': 0.7674307}, {'name': 'right_hip', 'x': 0.77141535, 'y': 0.41100162, 'score': 0.77271837}, {'name': 'left_knee', 'x': 0.80912805, 'y': 0.85941356, 'score': 0.21782893}, {'name': 'right_knee', 'x': 0.8494836, 'y': 0.13234848, 'score': 0.49091607}, {'name': 'left_ankle', 'x': 0.9329953, 'y': 0.44570383, 'score': 0.2447293}, {'name': 'right_ankle', 'x': 0.9305755, 'y': 0.5075178, 'score': 0.194656}]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Load the MoveNet model from TensorFlow Hub\n",
    "model = hub.load(\"https://tfhub.dev/google/movenet/singlepose/lightning/4\")\n",
    "\n",
    "# Function to process the image and prepare it for the model\n",
    "def preprocess_image(image_path, input_size=192):\n",
    "    if not os.path.exists(image_path):\n",
    "        raise FileNotFoundError(f\"File {image_path} does not exist.\")\n",
    "    \n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Failed to read the image {image_path}.\")\n",
    "    \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (input_size, input_size))\n",
    "    img = img.astype(np.int32)  # Convert to int32\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    return img\n",
    "\n",
    "# Function to detect poses in the image\n",
    "def detect_pose(model, img):\n",
    "    img_tensor = tf.convert_to_tensor(img, dtype=tf.int32)  # Ensure the tensor is int32\n",
    "    outputs = model.signatures[\"serving_default\"](img_tensor)\n",
    "    keypoints = outputs['output_0'].numpy()\n",
    "    return keypoints\n",
    "\n",
    "# Function to draw keypoints and edges on the image\n",
    "def draw_keypoints(image, keypoints, confidence_threshold=0.1):\n",
    "    y, x, _ = image.shape\n",
    "    shaped = np.squeeze(np.multiply(keypoints, [y, x, 1]))\n",
    "\n",
    "    for kp in shaped:\n",
    "        ky, kx, kp_conf = kp\n",
    "        if kp_conf > confidence_threshold:\n",
    "            cv2.circle(image, (int(kx), int(ky)), 4, (0, 255, 0), -1)\n",
    "    return image\n",
    "\n",
    "# Path to the image\n",
    "image_path = 'frozen-shoulder-exercise/stage-2.png'\n",
    "\n",
    "# Preprocess the image\n",
    "processed_image = preprocess_image(image_path)\n",
    "\n",
    "# Detect the pose\n",
    "keypoints = detect_pose(model, processed_image)\n",
    "\n",
    "body_parts = [\n",
    "    \"nose\", \"left_eye\", \"right_eye\", \"left_ear\", \"right_ear\", \"left_shoulder\", \"right_shoulder\",\n",
    "    \"left_elbow\", \"right_elbow\", \"left_wrist\", \"right_wrist\", \"left_hip\", \"right_hip\",\n",
    "    \"left_knee\", \"right_knee\", \"left_ankle\", \"right_ankle\"\n",
    "]\n",
    "\n",
    "# Extract the keypoints for each body part and create the required dictionary format\n",
    "formatted_keypoints = []\n",
    "for i, part in enumerate(body_parts):\n",
    "    kp = keypoints[0, 0, i]\n",
    "    formatted_keypoints.append({\n",
    "        \"name\": part,\n",
    "        \"x\": kp[0],\n",
    "        \"y\": kp[1],\n",
    "        \"score\": kp[2]\n",
    "    })\n",
    "\n",
    "# Print the formatted keypoints\n",
    "print(formatted_keypoints)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
